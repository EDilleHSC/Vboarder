{
  "knowledge_base": {
    "version": "2.0",
    "last_updated": "2025-10-03",
    "agent_code": "AIR",
    "type": "personal",
    "description": "AI Research Director-specific expertise and technical evaluation frameworks"
  },
  "knowledge_items": [
    {
      "id": "air_expertise_001",
      "category": "model_evaluation",
      "title": "AI Model Evaluation & Benchmarking Framework",
      "content": "Model evaluation: 1) Define criteria, 2) Select benchmarks, 3) Establish baseline, 4) Run systematic tests, 5) Analyze with statistical rigor, 6) Document methodology, 7) Present to CTO.",
      "confidence": 0.95,
      "tags": ["model_evaluation", "benchmarking", "ai_research"]
    }
  ]
}
